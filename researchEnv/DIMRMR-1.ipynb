{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3om5b7ViaZ0_",
    "outputId": "4840f409-cdd0-423e-ada8-5fc4ad97c4c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: caimcaim in ./lib/python3.8/site-packages (0.3)\n",
      "Requirement already satisfied: pandas in ./lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in ./lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: xgboost in ./lib/python3.8/site-packages (1.7.5)\n",
      "Requirement already satisfied: numpy in ./lib/python3.8/site-packages (from caimcaim) (1.24.3)\n",
      "Requirement already satisfied: sklearn in ./lib/python3.8/site-packages (from caimcaim) (0.0.post5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in ./lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install caimcaim pandas scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "J9pec9xsYESA",
    "outputId": "940341e9-2204-43e7-af39-967448623870"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from IPython.display import  clear_output\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from caimcaim import CAIMD\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "CKNVGHWvYKlA"
   },
   "outputs": [],
   "source": [
    "def entropy(X):\n",
    "    unique, count = np.unique(X, return_counts=True, axis=0)\n",
    "    prob = count / len(X)\n",
    "    en = np.sum((-1) * prob * np.log2(prob))\n",
    "    return en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "rlocyhjyYQ5v"
   },
   "outputs": [],
   "source": [
    "# Joint Entropy H(x,y)\n",
    "def joint_entropy(X, Y):\n",
    "    XY = np.c_[X, Y] \n",
    "    return entropy(XY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "Y5LDDEaBYTu_"
   },
   "outputs": [],
   "source": [
    "# Joint Entropy H(x,y,z)\n",
    "def joint_entropy_3(X, Y, Z):\n",
    "    XYZ = np.c_[X, Y, Z]\n",
    "    return entropy(XYZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "qsMtrpWrYe0v"
   },
   "outputs": [],
   "source": [
    "# Conditional Entropy X given Y; H(x|y)\n",
    "def conditional_entropy(X, Y):\n",
    "    return joint_entropy(X, Y) - entropy(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "VvR1xpSjYh4N"
   },
   "outputs": [],
   "source": [
    "def ret_joint_entropy3(x,y):\n",
    "    if(x<y):\n",
    "        return joint_entropy_list3[x][y]\n",
    "    else:\n",
    "        return joint_entropy_list3[y][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "WXeUgwjYYlkX"
   },
   "outputs": [],
   "source": [
    "\n",
    "def ret_joint_entropy(x,y):\n",
    "    if(x<y):\n",
    "        return joint_entropy_list[x][y]\n",
    "    else:\n",
    "        return joint_entropy_list[y][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "1Zh4WodeYoSO"
   },
   "outputs": [],
   "source": [
    "#### H(x,y|z)\n",
    "def conditional_join_entropy(x, y, z):\n",
    "    if x == length - 1:\n",
    "        return ret_joint_entropy3(y, z) - entropy_list[z];\n",
    "    elif y == length - 1:\n",
    "        return ret_joint_entropy3(x, z) - entropy_list[z];\n",
    "    else:\n",
    "        return ret_joint_entropy3(x, y) - entropy_list[z];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "ToY-jidjYr13"
   },
   "outputs": [],
   "source": [
    "##### I(x,y)\n",
    "def get_mutual_info(x, y):\n",
    "    return entropy_list[x] + entropy_list[y] - ret_joint_entropy(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "01Jm-Y1vYxP2"
   },
   "outputs": [],
   "source": [
    "########## I(x,y|z)\n",
    "def conditional_mutual_info(x, y, z):\n",
    "    cxz = ret_joint_entropy(x, z)-entropy_list[z];\n",
    "    cyz = ret_joint_entropy(y, z)-entropy_list[z];\n",
    "    return cxz + cyz - conditional_join_entropy(x, y, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "2CH2HqKPY3JP"
   },
   "outputs": [],
   "source": [
    "def feature_name(arr):\n",
    "    name = \"{\";\n",
    "    for i in range(len(arr)):\n",
    "        if i > 0:\n",
    "            name = name + \", \";\n",
    "\n",
    "        name = name + feature_list[arr[i]]\n",
    "\n",
    "    name = name + \"}\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "jdd8RosuY6bI"
   },
   "outputs": [],
   "source": [
    "def feature_array(arr):\n",
    "    name = []\n",
    "    for i in range(len(arr)):\n",
    "        name.append(feature_list[arr[i]])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "1eEHsioDY9DW"
   },
   "outputs": [],
   "source": [
    "def return_corelation(x, y):\n",
    "    size = len(x);\n",
    "    ux = x.sum() / size\n",
    "    uy = y.sum() / size\n",
    "\n",
    "    xmux = x - ux\n",
    "    ymuy = y - uy\n",
    "\n",
    "    xmuxymuy = xmux * ymuy;\n",
    "\n",
    "    cov = xmuxymuy.sum() / (size - 1)\n",
    "\n",
    "    var_x = xmux * xmux\n",
    "    var_x = var_x.sum() / (size - 1)\n",
    "\n",
    "    var_y = ymuy * ymuy\n",
    "    var_y = var_y.sum() / (size - 1)\n",
    "\n",
    "    sd_x = math.sqrt(var_x)\n",
    "    sd_y = math.sqrt(var_y)\n",
    "\n",
    "    co_xy = cov / (sd_x * sd_y)\n",
    "\n",
    "    return co_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "nXOR_xGzY_q_"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_svm(selected_features):\n",
    "    x = data[selected_features];\n",
    "    y = data['class'];\n",
    "\n",
    "    model = SVC(gamma='auto', C=10, kernel='linear')\n",
    "    accuracy = cross_validation(model, x, y)\n",
    "    return accuracy;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "PdPLyDP6ZDAY"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_dt(selected_features):\n",
    "\n",
    "    x = data[selected_features];\n",
    "    y = data['class'];\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    accuracy = cross_validation(model, x, y)\n",
    "    return accuracy;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "LTa5Fjt0ZGMI"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_KNN(selected_features):\n",
    "\n",
    "  x = data[selected_features];\n",
    "  y = data['class'];\n",
    "\n",
    "  model = KNeighborsClassifier(n_neighbors=3)\n",
    "  accuracy = cross_validation(model, x, y)\n",
    "  return accuracy;\n",
    "\n",
    "  return accuracy_score(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "7HMoILsjZJbm"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_nb(selected_features):\n",
    "\n",
    "  x = data[selected_features];\n",
    "  y = data['class'];\n",
    "\n",
    "  model = GaussianNB()\n",
    "\n",
    "  accuracy = cross_validation(model, x, y)\n",
    "  return accuracy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "ky80lJeBZMtn"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_xgb(selected_features):\n",
    "    x = data[selected_features];\n",
    "    y = data['class'];\n",
    "\n",
    "    model = XGBClassifier()\n",
    "\n",
    "    accuracy = cross_validation(model, x, y)\n",
    "    return accuracy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "aA4ZJjbYZQWP"
   },
   "outputs": [],
   "source": [
    "def cross_validation(model, _X, _y):\n",
    "    _scoring = ['accuracy', 'precision', 'recall', 'test_score']\n",
    "    results = cross_validate(estimator=model,\n",
    "                             X=_X,\n",
    "                             y=_y,\n",
    "                             cv=10,\n",
    "                             # scoring=_scoring,\n",
    "                             return_train_score=True)\n",
    "\n",
    "    return results['test_score'].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "FhC5EJsbZTfP"
   },
   "outputs": [],
   "source": [
    "def ret_covariance(x,y):\n",
    "    return covariance_list[x][y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "h_NjrpMSZWuX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data RELATHE_discreate\n"
     ]
    }
   ],
   "source": [
    "print(\"Load Data RELATHE_discreate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "-e0ni8-KZcQH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10992, 17)\n"
     ]
    }
   ],
   "source": [
    "main_data = pd.read_csv(\"pendigits.csv\")\n",
    "clear_output()\n",
    "print(main_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "4j-hlntbZfoW"
   },
   "outputs": [],
   "source": [
    "feature_list = main_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "X57ML-poZih1"
   },
   "outputs": [],
   "source": [
    "caim = CAIMD()\n",
    "x = main_data[feature_list[:-1]];\n",
    "y = main_data['class'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "IeDFXSSVZnt_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0  GLOBAL CAIM  97.98861085672317\n",
      "# 1  GLOBAL CAIM  127.52179668015063\n",
      "# 2  GLOBAL CAIM  70.69479583427037\n",
      "# 3  GLOBAL CAIM  101.67496475466642\n",
      "# 4  GLOBAL CAIM  109.78659760885364\n",
      "# 5  GLOBAL CAIM  146.48743397661866\n",
      "# 6  GLOBAL CAIM  98.85261390017756\n",
      "# 7  GLOBAL CAIM  162.63023326307626\n",
      "# 8  GLOBAL CAIM  72.82436463178126\n",
      "# 9  GLOBAL CAIM  118.59612313091051\n",
      "# 10  GLOBAL CAIM  76.70440033288963\n",
      "# 11  GLOBAL CAIM  111.99841534555728\n",
      "# 12  GLOBAL CAIM  80.75074886932973\n",
      "# 13  GLOBAL CAIM  166.7675540264832\n",
      "# 14  GLOBAL CAIM  109.94047950292438\n",
      "# 15  GLOBAL CAIM  184.838964313185\n"
     ]
    }
   ],
   "source": [
    "x_disc = caim.fit_transform(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "j4Cmd5OjZqcn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10992, 17)\n"
     ]
    }
   ],
   "source": [
    "data = x_disc\n",
    "data['class'] = y;\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afRS1pMCZvxW"
   },
   "source": [
    "parameters = {'n_estimators': [200, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion':['gini', 'entropy', 'log_loss']}\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "clf = GridSearchCV(rfc, parameters)\n",
    "x = data[feature_list[:-1]]\n",
    "y = data['class'];\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1, stratify=y)\n",
    "clf.fit(x, y)\n",
    "sorted(clf.cv_results_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "print(\"Random Forest Accuracy with all columns\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "-CBwY2LfZzW2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0\n",
      "x: 1\n",
      "x: 2\n",
      "x: 3\n",
      "x: 4\n",
      "x: 5\n",
      "x: 6\n",
      "x: 7\n",
      "x: 8\n",
      "x: 9\n",
      "x: 10\n",
      "x: 11\n",
      "x: 12\n",
      "x: 13\n",
      "x: 14\n",
      "x: 15\n",
      "x: 16\n",
      "populate Data\n"
     ]
    }
   ],
   "source": [
    "length=len(feature_list)\n",
    "entropy_list = [0]*length;\n",
    "joint_entropy_list = defaultdict(dict);\n",
    "conditional_entropy_list = defaultdict(dict);\n",
    "joint_entropy_list3 = defaultdict(dict);\n",
    "covariance_list = defaultdict(dict);\n",
    "for i in range(length):\n",
    "    entropy_list[i] = entropy(data[feature_list[i]])\n",
    "    for j in range(i,length):\n",
    "        joint_entropy_list[i][j] = joint_entropy(data[feature_list[i]],data[feature_list[j]])\n",
    "        joint_entropy_list3[i][j] = joint_entropy_3(data[feature_list[i]],data[feature_list[j]],data[feature_list[length-1]]);\n",
    "\n",
    "    print(\"x: %s\" %(i))\n",
    "\n",
    "\n",
    "for i in range(length):\n",
    "  for j in range(length):\n",
    "    conditional_entropy_list[i][j] = ret_joint_entropy(i,j)-entropy_list[j];\n",
    "    covariance_list[i][j] = return_corelation(data[feature_list[i]],data[feature_list[j]])\n",
    "\n",
    "print(\"populate Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "BOKxhTlJZ3NP",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIMRMR features serially\n",
      "[15, 4, 9, 14, 13, 1, 0, 7, 10, 8, 5, 11, 6, 3, 12, 2]\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################## DIMRMR ########################\n",
    "print(\"DIMRMR features serially\")\n",
    "xk = [];\n",
    "current_mi = 0;\n",
    "loop_counter = 100 if (length-1)>100 else length-1;\n",
    "# print(feature_list)\n",
    "\n",
    "while len(xk) < loop_counter:\n",
    "    di = [-100] * (length - 1);\n",
    "    dimrmr = [-100] * (length - 1);\n",
    "    dijmi = [-1] * (length - 1);\n",
    "    # print(f\"F = %s\"%feature_name(xk))\n",
    "\n",
    "    for i in range(length - 1):\n",
    "        if (i in xk):\n",
    "            continue;\n",
    "\n",
    "        avg_dep = 0\n",
    "        iFcfk = 0\n",
    "        # print(feature_list[i])\n",
    "\n",
    "        for j in range(len(xk)):\n",
    "            avg_dep += conditional_mutual_info(i, length - 1, xk[j])\n",
    "            iFcfk += conditional_mutual_info(xk[j], length - 1, i)\n",
    "\n",
    "        if (len(xk)):\n",
    "            avg_dep = avg_dep / len(xk);\n",
    "            iFcfk = iFcfk / len(xk);\n",
    "\n",
    "        cr = avg_dep - get_mutual_info(i, length - 1)\n",
    "\n",
    "        cr_st = 2 * (cr) / (entropy_list[i] + entropy_list[length - 1])\n",
    "\n",
    "        di[i] = (2 + cr_st) * (iFcfk);\n",
    "\n",
    "        ifkxk = 0\n",
    "\n",
    "        icfk = get_mutual_info(i, length - 1);\n",
    "        for j in range(len(xk)):\n",
    "            ifkxk += get_mutual_info(i, xk[j])\n",
    "\n",
    "        if (len(xk)):\n",
    "            ifkxk = ifkxk / len(xk);\n",
    "\n",
    "        dimrmr[i] = (icfk - ifkxk) * di[i];\n",
    "\n",
    "        # F = xk.copy();\n",
    "        # F.append(i)\n",
    "\n",
    "    (m, p) = max((v, i) for i, v in enumerate(dimrmr))\n",
    "    xk.append(p)\n",
    "\n",
    "print(xk)\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Random Forest Accuracy\n",
      "0.8258064516129032\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators': [200, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion':['gini', 'entropy', 'log_loss']}\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "clf = GridSearchCV(rfc, parameters)\n",
    "column_positions = [255, 29, 114, 119, 193, 77]\n",
    "x = data.iloc[:, column_positions]\n",
    "y = data['class'];\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1, stratify=y)\n",
    "clf.fit(x, y)\n",
    "sorted(clf.cv_results_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "print(\"Random Forest Accuracy\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 0 Random Forest Accuracy: Using features [255, 29, 114]\n",
      "0.646236559139785\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 1 Random Forest Accuracy: Using features [255, 29, 119]\n",
      "0.6209677419354839\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 2 Random Forest Accuracy: Using features [255, 29, 193]\n",
      "0.5924731182795699\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 3 Random Forest Accuracy: Using features [255, 29, 77]\n",
      "0.6016129032258064\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 4 Random Forest Accuracy: Using features [255, 114, 119]\n",
      "0.6204301075268818\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 5 Random Forest Accuracy: Using features [255, 114, 193]\n",
      "0.5865591397849462\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 6 Random Forest Accuracy: Using features [255, 114, 77]\n",
      "0.6403225806451613\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 7 Random Forest Accuracy: Using features [255, 119, 193]\n",
      "0.5736559139784946\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 8 Random Forest Accuracy: Using features [255, 119, 77]\n",
      "0.6118279569892473\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 9 Random Forest Accuracy: Using features [255, 193, 77]\n",
      "0.5903225806451613\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 10 Random Forest Accuracy: Using features [29, 114, 119]\n",
      "0.6172043010752688\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 11 Random Forest Accuracy: Using features [29, 114, 193]\n",
      "0.7053763440860215\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 12 Random Forest Accuracy: Using features [29, 114, 77]\n",
      "0.6279569892473118\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 13 Random Forest Accuracy: Using features [29, 119, 193]\n",
      "0.6505376344086021\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 14 Random Forest Accuracy: Using features [29, 119, 77]\n",
      "0.5956989247311828\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 15 Random Forest Accuracy: Using features [29, 193, 77]\n",
      "0.6591397849462366\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 16 Random Forest Accuracy: Using features [114, 119, 193]\n",
      "0.6854838709677419\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 17 Random Forest Accuracy: Using features [114, 119, 77]\n",
      "0.6220430107526882\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 18 Random Forest Accuracy: Using features [114, 193, 77]\n",
      "0.7118279569892473\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 19 Random Forest Accuracy: Using features [119, 193, 77]\n",
      "0.6666666666666666\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "items = [255, 29, 114, 119, 193, 77]\n",
    "selected_combinations = list(combinations(items, 3))\n",
    "\n",
    "tries = len(selected_combinations)\n",
    "\n",
    "for i in range(0, (tries)):\n",
    "    features = list(selected_combinations[i])\n",
    "\n",
    "    parameters = {'n_estimators': [200, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion':['gini', 'entropy', 'log_loss']}\n",
    "    rfc=RandomForestClassifier(random_state=42)\n",
    "    clf = GridSearchCV(rfc, parameters)\n",
    "    x = data.iloc[:, features]\n",
    "    y = data['class'];\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1, stratify=y)\n",
    "    clf.fit(x, y)\n",
    "    sorted(clf.cv_results_)\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    predictions = clf.predict(x_test)\n",
    "    print(f\"Try no. {i} Random Forest Accuracy: Using features {features}\")\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    print(\"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
