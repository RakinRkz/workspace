{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3om5b7ViaZ0_",
    "outputId": "4840f409-cdd0-423e-ada8-5fc4ad97c4c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: caimcaim in ./lib/python3.8/site-packages (0.3)\n",
      "Requirement already satisfied: pandas in ./lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in ./lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: xgboost in ./lib/python3.8/site-packages (1.7.5)\n",
      "Requirement already satisfied: numpy in ./lib/python3.8/site-packages (from caimcaim) (1.24.3)\n",
      "Requirement already satisfied: sklearn in ./lib/python3.8/site-packages (from caimcaim) (0.0.post5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in ./lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install caimcaim pandas scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "J9pec9xsYESA",
    "outputId": "940341e9-2204-43e7-af39-967448623870"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from IPython.display import  clear_output\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from caimcaim import CAIMD\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "CKNVGHWvYKlA"
   },
   "outputs": [],
   "source": [
    "def entropy(X):\n",
    "    unique, count = np.unique(X, return_counts=True, axis=0)\n",
    "    prob = count / len(X)\n",
    "    en = np.sum((-1) * prob * np.log2(prob))\n",
    "    return en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "rlocyhjyYQ5v"
   },
   "outputs": [],
   "source": [
    "# Joint Entropy H(x,y)\n",
    "def joint_entropy(X, Y):\n",
    "    XY = np.c_[X, Y] \n",
    "    return entropy(XY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "Y5LDDEaBYTu_"
   },
   "outputs": [],
   "source": [
    "# Joint Entropy H(x,y,z)\n",
    "def joint_entropy_3(X, Y, Z):\n",
    "    XYZ = np.c_[X, Y, Z]\n",
    "    return entropy(XYZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "qsMtrpWrYe0v"
   },
   "outputs": [],
   "source": [
    "# Conditional Entropy X given Y; H(x|y)\n",
    "def conditional_entropy(X, Y):\n",
    "    return joint_entropy(X, Y) - entropy(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "VvR1xpSjYh4N"
   },
   "outputs": [],
   "source": [
    "def ret_joint_entropy3(x,y):\n",
    "    if(x<y):\n",
    "        return joint_entropy_list3[x][y]\n",
    "    else:\n",
    "        return joint_entropy_list3[y][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "WXeUgwjYYlkX"
   },
   "outputs": [],
   "source": [
    "\n",
    "def ret_joint_entropy(x,y):\n",
    "    if(x<y):\n",
    "        return joint_entropy_list[x][y]\n",
    "    else:\n",
    "        return joint_entropy_list[y][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "1Zh4WodeYoSO"
   },
   "outputs": [],
   "source": [
    "#### H(x,y|z)\n",
    "def conditional_join_entropy(x, y, z):\n",
    "    if x == length - 1:\n",
    "        return ret_joint_entropy3(y, z) - entropy_list[z];\n",
    "    elif y == length - 1:\n",
    "        return ret_joint_entropy3(x, z) - entropy_list[z];\n",
    "    else:\n",
    "        return ret_joint_entropy3(x, y) - entropy_list[z];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "ToY-jidjYr13"
   },
   "outputs": [],
   "source": [
    "##### I(x,y)\n",
    "def get_mutual_info(x, y):\n",
    "    return entropy_list[x] + entropy_list[y] - ret_joint_entropy(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "01Jm-Y1vYxP2"
   },
   "outputs": [],
   "source": [
    "########## I(x,y|z)\n",
    "def conditional_mutual_info(x, y, z):\n",
    "    cxz = ret_joint_entropy(x, z)-entropy_list[z];\n",
    "    cyz = ret_joint_entropy(y, z)-entropy_list[z];\n",
    "    return cxz + cyz - conditional_join_entropy(x, y, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "2CH2HqKPY3JP"
   },
   "outputs": [],
   "source": [
    "def feature_name(arr):\n",
    "    name = \"{\";\n",
    "    for i in range(len(arr)):\n",
    "        if i > 0:\n",
    "            name = name + \", \";\n",
    "\n",
    "        name = name + feature_list[arr[i]]\n",
    "\n",
    "    name = name + \"}\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "jdd8RosuY6bI"
   },
   "outputs": [],
   "source": [
    "def feature_array(arr):\n",
    "    name = []\n",
    "    for i in range(len(arr)):\n",
    "        name.append(feature_list[arr[i]])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "1eEHsioDY9DW"
   },
   "outputs": [],
   "source": [
    "def return_corelation(x, y):\n",
    "    size = len(x);\n",
    "    ux = x.sum() / size\n",
    "    uy = y.sum() / size\n",
    "\n",
    "    xmux = x - ux\n",
    "    ymuy = y - uy\n",
    "\n",
    "    xmuxymuy = xmux * ymuy;\n",
    "\n",
    "    cov = xmuxymuy.sum() / (size - 1)\n",
    "\n",
    "    var_x = xmux * xmux\n",
    "    var_x = var_x.sum() / (size - 1)\n",
    "\n",
    "    var_y = ymuy * ymuy\n",
    "    var_y = var_y.sum() / (size - 1)\n",
    "\n",
    "    sd_x = math.sqrt(var_x)\n",
    "    sd_y = math.sqrt(var_y)\n",
    "\n",
    "    co_xy = cov / (sd_x * sd_y)\n",
    "\n",
    "    return co_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "nXOR_xGzY_q_"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_svm(selected_features):\n",
    "    x = data[selected_features];\n",
    "    y = data['class'];\n",
    "\n",
    "    model = SVC(gamma='auto', C=10, kernel='linear')\n",
    "    accuracy = cross_validation(model, x, y)\n",
    "    return accuracy;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "PdPLyDP6ZDAY"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_dt(selected_features):\n",
    "\n",
    "    x = data[selected_features];\n",
    "    y = data['class'];\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    accuracy = cross_validation(model, x, y)\n",
    "    return accuracy;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "LTa5Fjt0ZGMI"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_KNN(selected_features):\n",
    "\n",
    "  x = data[selected_features];\n",
    "  y = data['class'];\n",
    "\n",
    "  model = KNeighborsClassifier(n_neighbors=3)\n",
    "  accuracy = cross_validation(model, x, y)\n",
    "  return accuracy;\n",
    "\n",
    "  return accuracy_score(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "7HMoILsjZJbm"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_nb(selected_features):\n",
    "\n",
    "  x = data[selected_features];\n",
    "  y = data['class'];\n",
    "\n",
    "  model = GaussianNB()\n",
    "\n",
    "  accuracy = cross_validation(model, x, y)\n",
    "  return accuracy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "ky80lJeBZMtn"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_xgb(selected_features):\n",
    "    x = data[selected_features];\n",
    "    y = data['class'];\n",
    "\n",
    "    model = XGBClassifier()\n",
    "\n",
    "    accuracy = cross_validation(model, x, y)\n",
    "    return accuracy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "aA4ZJjbYZQWP"
   },
   "outputs": [],
   "source": [
    "def cross_validation(model, _X, _y):\n",
    "    _scoring = ['accuracy', 'precision', 'recall', 'test_score']\n",
    "    results = cross_validate(estimator=model,\n",
    "                             X=_X,\n",
    "                             y=_y,\n",
    "                             cv=10,\n",
    "                             # scoring=_scoring,\n",
    "                             return_train_score=True)\n",
    "\n",
    "    return results['test_score'].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "FhC5EJsbZTfP"
   },
   "outputs": [],
   "source": [
    "def ret_covariance(x,y):\n",
    "    return covariance_list[x][y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "h_NjrpMSZWuX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data RELATHE_discreate\n"
     ]
    }
   ],
   "source": [
    "print(\"Load Data RELATHE_discreate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "-e0ni8-KZcQH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9298, 257)\n"
     ]
    }
   ],
   "source": [
    "main_data = pd.read_csv(\"USPS_discreate.csv\")\n",
    "clear_output()\n",
    "print(main_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "4j-hlntbZfoW"
   },
   "outputs": [],
   "source": [
    "feature_list = main_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "X57ML-poZih1"
   },
   "outputs": [],
   "source": [
    "caim = CAIMD()\n",
    "x = main_data[feature_list[:-1]];\n",
    "y = main_data['class'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "IeDFXSSVZnt_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]\n"
     ]
    }
   ],
   "source": [
    "x_disc = caim.fit_transform(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "j4Cmd5OjZqcn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9298, 257)\n"
     ]
    }
   ],
   "source": [
    "data = x_disc\n",
    "data['class'] = y;\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "afRS1pMCZvxW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Random Forest Accuracy\n",
      "0.9731182795698925\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators': [200, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion':['gini', 'entropy', 'log_loss']}\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "clf = GridSearchCV(rfc, parameters)\n",
    "x = data[feature_list[:-1]]\n",
    "y = data['class'];\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1, stratify=y)\n",
    "clf.fit(x, y)\n",
    "sorted(clf.cv_results_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "print(\"Random Forest Accuracy\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "-CBwY2LfZzW2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0\n",
      "x: 1\n",
      "x: 2\n",
      "x: 3\n",
      "x: 4\n",
      "x: 5\n",
      "x: 6\n",
      "x: 7\n",
      "x: 8\n",
      "x: 9\n",
      "x: 10\n",
      "x: 11\n",
      "x: 12\n",
      "x: 13\n",
      "x: 14\n",
      "x: 15\n",
      "x: 16\n",
      "x: 17\n",
      "x: 18\n",
      "x: 19\n",
      "x: 20\n",
      "x: 21\n",
      "x: 22\n",
      "x: 23\n",
      "x: 24\n",
      "x: 25\n",
      "x: 26\n",
      "x: 27\n",
      "x: 28\n",
      "x: 29\n",
      "x: 30\n",
      "x: 31\n",
      "x: 32\n",
      "x: 33\n",
      "x: 34\n",
      "x: 35\n",
      "x: 36\n",
      "x: 37\n",
      "x: 38\n",
      "x: 39\n",
      "x: 40\n",
      "x: 41\n",
      "x: 42\n",
      "x: 43\n",
      "x: 44\n",
      "x: 45\n",
      "x: 46\n",
      "x: 47\n",
      "x: 48\n",
      "x: 49\n",
      "x: 50\n",
      "x: 51\n",
      "x: 52\n",
      "x: 53\n",
      "x: 54\n",
      "x: 55\n",
      "x: 56\n",
      "x: 57\n",
      "x: 58\n",
      "x: 59\n",
      "x: 60\n",
      "x: 61\n",
      "x: 62\n",
      "x: 63\n",
      "x: 64\n",
      "x: 65\n",
      "x: 66\n",
      "x: 67\n",
      "x: 68\n",
      "x: 69\n",
      "x: 70\n",
      "x: 71\n",
      "x: 72\n",
      "x: 73\n",
      "x: 74\n",
      "x: 75\n",
      "x: 76\n",
      "x: 77\n",
      "x: 78\n",
      "x: 79\n",
      "x: 80\n",
      "x: 81\n",
      "x: 82\n",
      "x: 83\n",
      "x: 84\n",
      "x: 85\n",
      "x: 86\n",
      "x: 87\n",
      "x: 88\n",
      "x: 89\n",
      "x: 90\n",
      "x: 91\n",
      "x: 92\n",
      "x: 93\n",
      "x: 94\n",
      "x: 95\n",
      "x: 96\n",
      "x: 97\n",
      "x: 98\n",
      "x: 99\n",
      "x: 100\n",
      "x: 101\n",
      "x: 102\n",
      "x: 103\n",
      "x: 104\n",
      "x: 105\n",
      "x: 106\n",
      "x: 107\n",
      "x: 108\n",
      "x: 109\n",
      "x: 110\n",
      "x: 111\n",
      "x: 112\n",
      "x: 113\n",
      "x: 114\n",
      "x: 115\n",
      "x: 116\n",
      "x: 117\n",
      "x: 118\n",
      "x: 119\n",
      "x: 120\n",
      "x: 121\n",
      "x: 122\n",
      "x: 123\n",
      "x: 124\n",
      "x: 125\n",
      "x: 126\n",
      "x: 127\n",
      "x: 128\n",
      "x: 129\n",
      "x: 130\n",
      "x: 131\n",
      "x: 132\n",
      "x: 133\n",
      "x: 134\n",
      "x: 135\n",
      "x: 136\n",
      "x: 137\n",
      "x: 138\n",
      "x: 139\n",
      "x: 140\n",
      "x: 141\n",
      "x: 142\n",
      "x: 143\n",
      "x: 144\n",
      "x: 145\n",
      "x: 146\n",
      "x: 147\n",
      "x: 148\n",
      "x: 149\n",
      "x: 150\n",
      "x: 151\n",
      "x: 152\n",
      "x: 153\n",
      "x: 154\n",
      "x: 155\n",
      "x: 156\n",
      "x: 157\n",
      "x: 158\n",
      "x: 159\n",
      "x: 160\n",
      "x: 161\n",
      "x: 162\n",
      "x: 163\n",
      "x: 164\n",
      "x: 165\n",
      "x: 166\n",
      "x: 167\n",
      "x: 168\n",
      "x: 169\n",
      "x: 170\n",
      "x: 171\n",
      "x: 172\n",
      "x: 173\n",
      "x: 174\n",
      "x: 175\n",
      "x: 176\n",
      "x: 177\n",
      "x: 178\n",
      "x: 179\n",
      "x: 180\n",
      "x: 181\n",
      "x: 182\n",
      "x: 183\n",
      "x: 184\n",
      "x: 185\n",
      "x: 186\n",
      "x: 187\n",
      "x: 188\n",
      "x: 189\n",
      "x: 190\n",
      "x: 191\n",
      "x: 192\n",
      "x: 193\n",
      "x: 194\n",
      "x: 195\n",
      "x: 196\n",
      "x: 197\n",
      "x: 198\n",
      "x: 199\n",
      "x: 200\n",
      "x: 201\n",
      "x: 202\n",
      "x: 203\n",
      "x: 204\n",
      "x: 205\n",
      "x: 206\n",
      "x: 207\n",
      "x: 208\n",
      "x: 209\n",
      "x: 210\n",
      "x: 211\n",
      "x: 212\n",
      "x: 213\n",
      "x: 214\n",
      "x: 215\n",
      "x: 216\n",
      "x: 217\n",
      "x: 218\n",
      "x: 219\n",
      "x: 220\n",
      "x: 221\n",
      "x: 222\n",
      "x: 223\n",
      "x: 224\n",
      "x: 225\n",
      "x: 226\n",
      "x: 227\n",
      "x: 228\n",
      "x: 229\n",
      "x: 230\n",
      "x: 231\n",
      "x: 232\n",
      "x: 233\n",
      "x: 234\n",
      "x: 235\n",
      "x: 236\n",
      "x: 237\n",
      "x: 238\n",
      "x: 239\n",
      "x: 240\n",
      "x: 241\n",
      "x: 242\n",
      "x: 243\n",
      "x: 244\n",
      "x: 245\n",
      "x: 246\n",
      "x: 247\n",
      "x: 248\n",
      "x: 249\n",
      "x: 250\n",
      "x: 251\n",
      "x: 252\n",
      "x: 253\n",
      "x: 254\n",
      "x: 255\n",
      "x: 256\n",
      "populate Data\n"
     ]
    }
   ],
   "source": [
    "length=len(feature_list)\n",
    "entropy_list = [0]*length;\n",
    "joint_entropy_list = defaultdict(dict);\n",
    "conditional_entropy_list = defaultdict(dict);\n",
    "joint_entropy_list3 = defaultdict(dict);\n",
    "covariance_list = defaultdict(dict);\n",
    "for i in range(length):\n",
    "    entropy_list[i] = entropy(data[feature_list[i]])\n",
    "    for j in range(i,length):\n",
    "        joint_entropy_list[i][j] = joint_entropy(data[feature_list[i]],data[feature_list[j]])\n",
    "        joint_entropy_list3[i][j] = joint_entropy_3(data[feature_list[i]],data[feature_list[j]],data[feature_list[length-1]]);\n",
    "\n",
    "    print(\"x: %s\" %(i))\n",
    "\n",
    "\n",
    "for i in range(length):\n",
    "  for j in range(length):\n",
    "    conditional_entropy_list[i][j] = ret_joint_entropy(i,j)-entropy_list[j];\n",
    "    covariance_list[i][j] = return_corelation(data[feature_list[i]],data[feature_list[j]])\n",
    "\n",
    "print(\"populate Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "BOKxhTlJZ3NP",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFE\n",
      "[195, 92, 115, 133, 134, 102, 166, 165, 86, 89, 118, 150, 117, 73, 181, 154, 106, 88, 57, 121, 149, 122, 137, 170, 216, 153, 185, 105, 200, 201, 217, 138, 186, 169, 202, 198, 155, 215, 199, 214, 232, 184, 103, 90, 182, 231, 39, 183, 41, 56, 58, 104, 40, 87, 54, 74, 38, 85, 72, 70, 119, 152, 23, 55, 69, 71, 168, 53, 24, 135, 197, 7, 167, 148, 22, 249, 233, 10, 8, 120, 42, 9, 25, 151, 101, 6, 37, 171, 139, 136, 5, 26, 164, 15, 250, 230, 96, 64, 0, 252]\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"CIFE\")\n",
    "xk = [];\n",
    "current_mi = 0;\n",
    "loop_counter = 100 if (length-1)>100 else length-1;\n",
    "# print(feature_list)\n",
    "\n",
    "while len(xk) < loop_counter:\n",
    "    mi = [-100] * length;\n",
    "    current_mi = 0;\n",
    "\n",
    "    for i in range(length - 1):\n",
    "        if (i in xk):\n",
    "            continue;\n",
    "\n",
    "        Ixc = get_mutual_info(i, length - 1);\n",
    "        IxmxsC = 0;\n",
    "        for j in range(len(xk)):\n",
    "            IxmxsC += get_mutual_info(xk[j], i) - conditional_mutual_info(i, xk[j], length - 1);\n",
    "\n",
    "        # if(len(xk)):\n",
    "        #  Ixmxs = Ixmxs/len(xk);\n",
    "\n",
    "        mi[i] = Ixc - IxmxsC;\n",
    "\n",
    "    (m, p) = max((v, i) for i, v in enumerate(mi))\n",
    "    # print(mi)\n",
    "    xk.append(p)\n",
    "    # print(feature_name(xk))\n",
    "\n",
    "    # accurecy = selection_accurecy_dt(feature_array(xk))\n",
    "    # accurecy2 = selection_accurecy_svm(feature_array(xk))\n",
    "    # accurecy3 = selection_accurecy_KNN(feature_array(xk))\n",
    "    # accurecy4 = selection_accurecy_nb(feature_array(xk))\n",
    "    # accurecy5 =0\n",
    "    # print(f\"%s;%s; %s;%s; %s\" % (accurecy, accurecy2, accurecy3, accurecy4, accurecy5));\n",
    "\n",
    "\n",
    "print(xk)\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Random Forest Accuracy\n",
      "0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators': [200, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion':['gini', 'entropy', 'log_loss']}\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "clf = GridSearchCV(rfc, parameters)\n",
    "column_positions = [195, 92, 115, 133, 134, 102]\n",
    "x = data.iloc[:, column_positions]\n",
    "y = data['class'];\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1, stratify=y)\n",
    "clf.fit(x, y)\n",
    "sorted(clf.cv_results_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "print(\"Random Forest Accuracy\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 0 Random Forest Accuracy: Using features [195, 92, 115]\n",
      "0.6833333333333333\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 1 Random Forest Accuracy: Using features [195, 92, 133]\n",
      "0.639247311827957\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 2 Random Forest Accuracy: Using features [195, 92, 134]\n",
      "0.646236559139785\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 3 Random Forest Accuracy: Using features [195, 92, 102]\n",
      "0.6268817204301075\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 4 Random Forest Accuracy: Using features [195, 115, 133]\n",
      "0.6682795698924732\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 5 Random Forest Accuracy: Using features [195, 115, 134]\n",
      "0.6661290322580645\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 6 Random Forest Accuracy: Using features [195, 115, 102]\n",
      "0.6672043010752688\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 7 Random Forest Accuracy: Using features [195, 133, 134]\n",
      "0.6134408602150537\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 8 Random Forest Accuracy: Using features [195, 133, 102]\n",
      "0.6086021505376344\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 9 Random Forest Accuracy: Using features [195, 134, 102]\n",
      "0.6161290322580645\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 10 Random Forest Accuracy: Using features [92, 115, 133]\n",
      "0.5897849462365592\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 11 Random Forest Accuracy: Using features [92, 115, 134]\n",
      "0.6172043010752688\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 12 Random Forest Accuracy: Using features [92, 115, 102]\n",
      "0.6091397849462366\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 13 Random Forest Accuracy: Using features [92, 133, 134]\n",
      "0.5849462365591398\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 14 Random Forest Accuracy: Using features [92, 133, 102]\n",
      "0.5521505376344086\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 15 Random Forest Accuracy: Using features [92, 134, 102]\n",
      "0.5618279569892473\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 16 Random Forest Accuracy: Using features [115, 133, 134]\n",
      "0.5532258064516129\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 17 Random Forest Accuracy: Using features [115, 133, 102]\n",
      "0.5865591397849462\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 18 Random Forest Accuracy: Using features [115, 134, 102]\n",
      "0.5973118279569892\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 19 Random Forest Accuracy: Using features [133, 134, 102]\n",
      "0.5413978494623656\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "items = [195, 92, 115, 133, 134, 102]\n",
    "selected_combinations = list(combinations(items, 3))\n",
    "\n",
    "tries = len(selected_combinations)\n",
    "\n",
    "for i in range(0, (tries)):\n",
    "    features = list(selected_combinations[i])\n",
    "\n",
    "    parameters = {'n_estimators': [200, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion':['gini', 'entropy', 'log_loss']}\n",
    "    rfc=RandomForestClassifier(random_state=42)\n",
    "    clf = GridSearchCV(rfc, parameters)\n",
    "    x = data.iloc[:, features]\n",
    "    y = data['class'];\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1, stratify=y)\n",
    "    clf.fit(x, y)\n",
    "    sorted(clf.cv_results_)\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    predictions = clf.predict(x_test)\n",
    "    print(f\"Try no. {i} Random Forest Accuracy: Using features {features}\")\n",
    "    print(accuracy_score(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
