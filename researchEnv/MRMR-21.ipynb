{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3om5b7ViaZ0_",
    "outputId": "4840f409-cdd0-423e-ada8-5fc4ad97c4c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: caimcaim in ./lib/python3.8/site-packages (0.3)\n",
      "Requirement already satisfied: pandas in ./lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in ./lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: xgboost in ./lib/python3.8/site-packages (1.7.5)\n",
      "Requirement already satisfied: numpy in ./lib/python3.8/site-packages (from caimcaim) (1.24.3)\n",
      "Requirement already satisfied: sklearn in ./lib/python3.8/site-packages (from caimcaim) (0.0.post5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in ./lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install caimcaim pandas scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "J9pec9xsYESA",
    "outputId": "940341e9-2204-43e7-af39-967448623870"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from IPython.display import  clear_output\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from caimcaim import CAIMD\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CKNVGHWvYKlA"
   },
   "outputs": [],
   "source": [
    "def entropy(X):\n",
    "    unique, count = np.unique(X, return_counts=True, axis=0)\n",
    "    prob = count / len(X)\n",
    "    en = np.sum((-1) * prob * np.log2(prob))\n",
    "    return en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rlocyhjyYQ5v"
   },
   "outputs": [],
   "source": [
    "# Joint Entropy H(x,y)\n",
    "def joint_entropy(X, Y):\n",
    "    XY = np.c_[X, Y] \n",
    "    return entropy(XY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Y5LDDEaBYTu_"
   },
   "outputs": [],
   "source": [
    "# Joint Entropy H(x,y,z)\n",
    "def joint_entropy_3(X, Y, Z):\n",
    "    XYZ = np.c_[X, Y, Z]\n",
    "    return entropy(XYZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qsMtrpWrYe0v"
   },
   "outputs": [],
   "source": [
    "# Conditional Entropy X given Y; H(x|y)\n",
    "def conditional_entropy(X, Y):\n",
    "    return joint_entropy(X, Y) - entropy(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VvR1xpSjYh4N"
   },
   "outputs": [],
   "source": [
    "def ret_joint_entropy3(x,y):\n",
    "    if(x<y):\n",
    "        return joint_entropy_list3[x][y]\n",
    "    else:\n",
    "        return joint_entropy_list3[y][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WXeUgwjYYlkX"
   },
   "outputs": [],
   "source": [
    "\n",
    "def ret_joint_entropy(x,y):\n",
    "    if(x<y):\n",
    "        return joint_entropy_list[x][y]\n",
    "    else:\n",
    "        return joint_entropy_list[y][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1Zh4WodeYoSO"
   },
   "outputs": [],
   "source": [
    "#### H(x,y|z)\n",
    "def conditional_join_entropy(x, y, z):\n",
    "    if x == length - 1:\n",
    "        return ret_joint_entropy3(y, z) - entropy_list[z];\n",
    "    elif y == length - 1:\n",
    "        return ret_joint_entropy3(x, z) - entropy_list[z];\n",
    "    else:\n",
    "        return ret_joint_entropy3(x, y) - entropy_list[z];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ToY-jidjYr13"
   },
   "outputs": [],
   "source": [
    "##### I(x,y)\n",
    "def get_mutual_info(x, y):\n",
    "    return entropy_list[x] + entropy_list[y] - ret_joint_entropy(x, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "01Jm-Y1vYxP2"
   },
   "outputs": [],
   "source": [
    "########## I(x,y|z)\n",
    "def conditional_mutual_info(x, y, z):\n",
    "    cxz = ret_joint_entropy(x, z)-entropy_list[z];\n",
    "    cyz = ret_joint_entropy(y, z)-entropy_list[z];\n",
    "    return cxz + cyz - conditional_join_entropy(x, y, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2CH2HqKPY3JP"
   },
   "outputs": [],
   "source": [
    "def feature_name(arr):\n",
    "    name = \"{\";\n",
    "    for i in range(len(arr)):\n",
    "        if i > 0:\n",
    "            name = name + \", \";\n",
    "\n",
    "        name = name + feature_list[arr[i]]\n",
    "\n",
    "    name = name + \"}\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jdd8RosuY6bI"
   },
   "outputs": [],
   "source": [
    "def feature_array(arr):\n",
    "    name = []\n",
    "    for i in range(len(arr)):\n",
    "        name.append(feature_list[arr[i]])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1eEHsioDY9DW"
   },
   "outputs": [],
   "source": [
    "def return_corelation(x, y):\n",
    "    size = len(x);\n",
    "    ux = x.sum() / size\n",
    "    uy = y.sum() / size\n",
    "\n",
    "    xmux = x - ux\n",
    "    ymuy = y - uy\n",
    "\n",
    "    xmuxymuy = xmux * ymuy;\n",
    "\n",
    "    cov = xmuxymuy.sum() / (size - 1)\n",
    "\n",
    "    var_x = xmux * xmux\n",
    "    var_x = var_x.sum() / (size - 1)\n",
    "\n",
    "    var_y = ymuy * ymuy\n",
    "    var_y = var_y.sum() / (size - 1)\n",
    "\n",
    "    sd_x = math.sqrt(var_x)\n",
    "    sd_y = math.sqrt(var_y)\n",
    "\n",
    "    co_xy = cov / (sd_x * sd_y)\n",
    "\n",
    "    return co_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nXOR_xGzY_q_"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_svm(selected_features):\n",
    "    x = data[selected_features];\n",
    "    y = data['class'];\n",
    "\n",
    "    model = SVC(gamma='auto', C=10, kernel='linear')\n",
    "    accuracy = cross_validation(model, x, y)\n",
    "    return accuracy;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PdPLyDP6ZDAY"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_dt(selected_features):\n",
    "\n",
    "    x = data[selected_features];\n",
    "    y = data['class'];\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    accuracy = cross_validation(model, x, y)\n",
    "    return accuracy;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LTa5Fjt0ZGMI"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_KNN(selected_features):\n",
    "\n",
    "  x = data[selected_features];\n",
    "  y = data['class'];\n",
    "\n",
    "  model = KNeighborsClassifier(n_neighbors=3)\n",
    "  accuracy = cross_validation(model, x, y)\n",
    "  return accuracy;\n",
    "\n",
    "  return accuracy_score(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7HMoILsjZJbm"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_nb(selected_features):\n",
    "\n",
    "  x = data[selected_features];\n",
    "  y = data['class'];\n",
    "\n",
    "  model = GaussianNB()\n",
    "\n",
    "  accuracy = cross_validation(model, x, y)\n",
    "  return accuracy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ky80lJeBZMtn"
   },
   "outputs": [],
   "source": [
    "def selection_accurecy_xgb(selected_features):\n",
    "    x = data[selected_features];\n",
    "    y = data['class'];\n",
    "\n",
    "    model = XGBClassifier()\n",
    "\n",
    "    accuracy = cross_validation(model, x, y)\n",
    "    return accuracy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aA4ZJjbYZQWP"
   },
   "outputs": [],
   "source": [
    "def cross_validation(model, _X, _y):\n",
    "    _scoring = ['accuracy', 'precision', 'recall', 'test_score']\n",
    "    results = cross_validate(estimator=model,\n",
    "                             X=_X,\n",
    "                             y=_y,\n",
    "                             cv=10,\n",
    "                             # scoring=_scoring,\n",
    "                             return_train_score=True)\n",
    "\n",
    "    return results['test_score'].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "FhC5EJsbZTfP"
   },
   "outputs": [],
   "source": [
    "def ret_covariance(x,y):\n",
    "    return covariance_list[x][y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "h_NjrpMSZWuX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data RELATHE_discreate\n"
     ]
    }
   ],
   "source": [
    "print(\"Load Data RELATHE_discreate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-e0ni8-KZcQH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494020, 42)\n"
     ]
    }
   ],
   "source": [
    "main_data = pd.read_csv(\"kddcup99.csv\")\n",
    "clear_output()\n",
    "print(main_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
       "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
       "       'num_failed_logins', 'logged_in', 'lnum_compromised', 'lroot_shell',\n",
       "       'lsu_attempted', 'lnum_root', 'lnum_file_creations', 'lnum_shells',\n",
       "       'lnum_access_files', 'lnum_outbound_cmds', 'is_host_login',\n",
       "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
       "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
       "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
       "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "       'dst_host_srv_rerror_rate', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "smurf              280790\n",
       "neptune            107201\n",
       "normal              97277\n",
       "back                 2203\n",
       "satan                1589\n",
       "ipsweep              1247\n",
       "portsweep            1040\n",
       "warezclient          1020\n",
       "teardrop              979\n",
       "pod                   264\n",
       "nmap                  231\n",
       "guess_passwd           53\n",
       "buffer_overflow        30\n",
       "land                   21\n",
       "warezmaster            20\n",
       "imap                   12\n",
       "rootkit                10\n",
       "loadmodule              9\n",
       "ftp_write               8\n",
       "multihop                7\n",
       "phf                     4\n",
       "perl                    3\n",
       "spy                     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data.value_counts('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>lnum_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>494020.000000</td>\n",
       "      <td>4.940200e+05</td>\n",
       "      <td>4.940200e+05</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "      <td>494020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47.979400</td>\n",
       "      <td>3.025616e+03</td>\n",
       "      <td>8.685308e+02</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.034519</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.148245</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>...</td>\n",
       "      <td>232.471248</td>\n",
       "      <td>188.666052</td>\n",
       "      <td>0.753781</td>\n",
       "      <td>0.030906</td>\n",
       "      <td>0.601936</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.176754</td>\n",
       "      <td>0.176443</td>\n",
       "      <td>0.058118</td>\n",
       "      <td>0.057412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>707.747185</td>\n",
       "      <td>9.882191e+05</td>\n",
       "      <td>3.304003e+04</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.134805</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.782103</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.355343</td>\n",
       "      <td>1.798328</td>\n",
       "      <td>...</td>\n",
       "      <td>64.744601</td>\n",
       "      <td>106.040205</td>\n",
       "      <td>0.410780</td>\n",
       "      <td>0.109259</td>\n",
       "      <td>0.481309</td>\n",
       "      <td>0.042133</td>\n",
       "      <td>0.380593</td>\n",
       "      <td>0.380920</td>\n",
       "      <td>0.230590</td>\n",
       "      <td>0.230141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.032000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58329.000000</td>\n",
       "      <td>6.933756e+08</td>\n",
       "      <td>5.155468e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>884.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            duration     src_bytes     dst_bytes           land  \\\n",
       "count  494020.000000  4.940200e+05  4.940200e+05  494020.000000   \n",
       "mean       47.979400  3.025616e+03  8.685308e+02       0.000045   \n",
       "std       707.747185  9.882191e+05  3.304003e+04       0.006673   \n",
       "min         0.000000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.000000  4.500000e+01  0.000000e+00       0.000000   \n",
       "50%         0.000000  5.200000e+02  0.000000e+00       0.000000   \n",
       "75%         0.000000  1.032000e+03  0.000000e+00       0.000000   \n",
       "max     58329.000000  6.933756e+08  5.155468e+06       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   494020.000000  494020.000000  494020.000000      494020.000000   \n",
       "mean         0.006433       0.000014       0.034519           0.000152   \n",
       "std          0.134805       0.005510       0.782103           0.015520   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      30.000000           5.000000   \n",
       "\n",
       "           logged_in  lnum_compromised  ...  dst_host_count  \\\n",
       "count  494020.000000     494020.000000  ...   494020.000000   \n",
       "mean        0.148245          0.010212  ...      232.471248   \n",
       "std         0.355343          1.798328  ...       64.744601   \n",
       "min         0.000000          0.000000  ...        0.000000   \n",
       "25%         0.000000          0.000000  ...      255.000000   \n",
       "50%         0.000000          0.000000  ...      255.000000   \n",
       "75%         0.000000          0.000000  ...      255.000000   \n",
       "max         1.000000        884.000000  ...      255.000000   \n",
       "\n",
       "       dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count       494020.000000           494020.000000           494020.000000   \n",
       "mean           188.666052                0.753781                0.030906   \n",
       "std            106.040205                0.410780                0.109259   \n",
       "min              0.000000                0.000000                0.000000   \n",
       "25%             46.000000                0.410000                0.000000   \n",
       "50%            255.000000                1.000000                0.000000   \n",
       "75%            255.000000                1.000000                0.040000   \n",
       "max            255.000000                1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                494020.000000                494020.000000   \n",
       "mean                      0.601936                     0.006684   \n",
       "std                       0.481309                     0.042133   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       1.000000                     0.000000   \n",
       "75%                       1.000000                     0.000000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count         494020.000000             494020.000000         494020.000000   \n",
       "mean               0.176754                  0.176443              0.058118   \n",
       "std                0.380593                  0.380920              0.230590   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                0.000000                  0.000000              0.000000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count             494020.000000  \n",
       "mean                   0.057412  \n",
       "std                    0.230141  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.000000  \n",
       "max                    1.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "4j-hlntbZfoW"
   },
   "outputs": [],
   "source": [
    "feature_list = main_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "X57ML-poZih1"
   },
   "outputs": [],
   "source": [
    "caim = CAIMD()\n",
    "x = main_data[feature_list[:-1]];\n",
    "y = main_data[feature_list[-1]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "IeDFXSSVZnt_"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_disc \u001b[39m=\u001b[39m caim\u001b[39m.\u001b[39;49mfit_transform(x, y)\n",
      "File \u001b[0;32m~/SharedFolder/IUT_Academic/Research/workspace/researchEnv/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/SharedFolder/IUT_Academic/Research/workspace/researchEnv/lib/python3.8/site-packages/caimcaim/caimcaim.py:175\u001b[0m, in \u001b[0;36mCAIMD.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m    171\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m    Fit CAIM to X,y, then discretize X.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39m    Equivalent to self.fit(X).transform(X)\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/SharedFolder/IUT_Academic/Research/workspace/researchEnv/lib/python3.8/site-packages/caimcaim/caimcaim.py:86\u001b[0m, in \u001b[0;36mCAIMD.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     84\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_features \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategorical \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_categorical(X, y)\n\u001b[1;32m     87\u001b[0m categorical \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategorical\n\u001b[1;32m     88\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCategorical\u001b[39m\u001b[39m'\u001b[39m, categorical)\n",
      "File \u001b[0;32m~/SharedFolder/IUT_Academic/Research/workspace/researchEnv/lib/python3.8/site-packages/caimcaim/caimcaim.py:204\u001b[0m, in \u001b[0;36mCAIMD.check_categorical\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[1;32m    203\u001b[0m     xj \u001b[39m=\u001b[39m X[:, j]\n\u001b[0;32m--> 204\u001b[0m     xj \u001b[39m=\u001b[39m xj[np\u001b[39m.\u001b[39minvert(np\u001b[39m.\u001b[39;49misnan(xj))]\n\u001b[1;32m    205\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39munique(xj)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m ny2:\n\u001b[1;32m    206\u001b[0m         categorical\u001b[39m.\u001b[39mappend(j)\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "x_disc = caim.fit_transform(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4Cmd5OjZqcn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10992, 17)\n"
     ]
    }
   ],
   "source": [
    "data = x_disc\n",
    "data['class'] = y;\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afRS1pMCZvxW"
   },
   "source": [
    "parameters = {'n_estimators': [200, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion':['gini', 'entropy', 'log_loss']}\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "clf = GridSearchCV(rfc, parameters)\n",
    "x = data[feature_list[:-1]]\n",
    "y = data['class'];\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1, stratify=y)\n",
    "clf.fit(x, y)\n",
    "sorted(clf.cv_results_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "print(\"Random Forest Accuracy with all columns\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CBwY2LfZzW2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0\n",
      "x: 1\n",
      "x: 2\n",
      "x: 3\n",
      "x: 4\n",
      "x: 5\n",
      "x: 6\n",
      "x: 7\n",
      "x: 8\n",
      "x: 9\n",
      "x: 10\n",
      "x: 11\n",
      "x: 12\n",
      "x: 13\n",
      "x: 14\n",
      "x: 15\n",
      "x: 16\n",
      "populate Data\n"
     ]
    }
   ],
   "source": [
    "length=len(feature_list)\n",
    "entropy_list = [0]*length;\n",
    "joint_entropy_list = defaultdict(dict);\n",
    "conditional_entropy_list = defaultdict(dict);\n",
    "joint_entropy_list3 = defaultdict(dict);\n",
    "covariance_list = defaultdict(dict);\n",
    "for i in range(length):\n",
    "    entropy_list[i] = entropy(data[feature_list[i]])\n",
    "    for j in range(i,length):\n",
    "        joint_entropy_list[i][j] = joint_entropy(data[feature_list[i]],data[feature_list[j]])\n",
    "        joint_entropy_list3[i][j] = joint_entropy_3(data[feature_list[i]],data[feature_list[j]],data[feature_list[length-1]]);\n",
    "\n",
    "    print(\"x: %s\" %(i))\n",
    "\n",
    "\n",
    "for i in range(length):\n",
    "  for j in range(length):\n",
    "    conditional_entropy_list[i][j] = ret_joint_entropy(i,j)-entropy_list[j];\n",
    "    covariance_list[i][j] = return_corelation(data[feature_list[i]],data[feature_list[j]])\n",
    "\n",
    "print(\"populate Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIM\n",
      "1.1581871371500716\n",
      "13\n",
      "1.13967040133993\n",
      "15\n",
      "0.9604890708114207\n",
      "7\n",
      "0.8237733029861234\n",
      "5\n",
      "0.7664921191560037\n",
      "9\n",
      "0.7262446945370309\n",
      "4\n",
      "0.7212929585792427\n",
      "14\n",
      "0.6928609213286885\n",
      "11\n",
      "0.6549877913007265\n",
      "1\n",
      "0.6346584904520167\n",
      "3\n",
      "0.625680461567474\n",
      "10\n",
      "0.6246388556069302\n",
      "0\n",
      "0.5724175129023799\n",
      "8\n",
      "0.462105304143952\n",
      "6\n",
      "0.3517099810363602\n",
      "2\n",
      "0.34409909949738626\n",
      "12\n",
      "[13, 15, 7, 5, 9, 4, 14, 11, 1, 3, 10, 0, 8, 6, 2, 12]\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"MIM\")\n",
    "xk = [];\n",
    "\n",
    "loop_counter = 100 if (length-1)>100 else length-1;\n",
    "# print(feature_list)\n",
    "while len(xk) < loop_counter:\n",
    "    mi = [-100] * length\n",
    " \n",
    "    for i in range(length - 1):\n",
    "        if (i in xk):\n",
    "            continue\n",
    "        mi[i] = get_mutual_info(i, length - 1)\n",
    "\n",
    "    (m, p) = max((v, i) for i, v in enumerate(mi))\n",
    "    print(m)\n",
    "    print(p)\n",
    "\n",
    "    xk.append(p)\n",
    "     #print(feature_name(xk))\n",
    "\n",
    "    \n",
    "print(xk)\n",
    "pref = xk[0];\n",
    "print('-----------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRMR max value 1.1581871371500716 for feature 13\n",
      "MRMR max value 0.553748589311228 for feature 4\n",
      "MRMR max value 0.5492193010824926 for feature 15\n",
      "MRMR max value 0.4782256515506562 for feature 9\n",
      "MRMR max value 0.4812555743032956 for feature 1\n",
      "MRMR max value 0.4951427033859259 for feature 14\n",
      "MRMR max value 0.49781900913774324 for feature 7\n",
      "MRMR max value 0.45154925822859293 for feature 0\n",
      "MRMR max value 0.4068501837871503 for feature 10\n",
      "MRMR max value 0.4226547332651389 for feature 5\n",
      "MRMR max value 0.35849838277832086 for feature 8\n",
      "MRMR max value 0.3279216645065841 for feature 11\n",
      "MRMR max value 0.30714084833755395 for feature 3\n",
      "MRMR max value 0.26652864770909257 for feature 6\n",
      "MRMR max value 0.20242798505143472 for feature 12\n",
      "MRMR max value 0.18504831325394538 for feature 2\n",
      "MRMR features serially\n",
      "[13, 4, 15, 9, 1, 14, 7, 0, 10, 5, 8, 11, 3, 6, 12, 2]\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "xk_mrmr = [] \n",
    "\n",
    "current_mi = 0 \n",
    "loop_counter = 100 if (length-1)>100 else length-1 \n",
    "# print(feature_list)\n",
    "\n",
    "while len(xk_mrmr) < loop_counter:\n",
    "    mi = [-100] * length\n",
    "    mrmr = [-100] * length\n",
    "    \n",
    "    for i in range(length - 1):\n",
    "        if (i in xk_mrmr):\n",
    "            continue \n",
    "\n",
    "        icfk = get_mutual_info(i, length - 1) #calculation done for MIM\n",
    "\n",
    "        mi[i] = icfk    #I (c; fk )\n",
    "        ifkxk = 0 #1/f x I (fk ; Xk ) the 2nd term of mrmr\n",
    "        for j in range(len(xk_mrmr)):\n",
    "            ifkxk += get_mutual_info(xk_mrmr[j], i)\n",
    "\n",
    "        if (len(xk_mrmr)):\n",
    "            ifkxk = ifkxk / len(xk_mrmr)\n",
    "\n",
    "        mrmr[i] = icfk - ifkxk  #calculation done for MRMR\n",
    "\n",
    "    \n",
    "    \n",
    "    (m, p) = max((v, i) for i, v in enumerate(mrmr))\n",
    "    xk_mrmr.append(p)\n",
    "\n",
    "    # if len(xk_mrmr) == 2:\n",
    "    #     print(mrmr)\n",
    "    #     print(f'{p}th column with highest mrmr value: {m}')\n",
    "\n",
    "    print(f'MRMR max value {m} for feature {p}')\n",
    "\n",
    "\n",
    "    # print(feature_name(xk))\n",
    "\n",
    "print(\"MRMR features serially\")    \n",
    "print(xk_mrmr)\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "id": "BOKxhTlJZ3NP",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max value 1.1581871371500716 for feature 13, DI value: 1, C ratio: -1.1581871371500716\n",
      "max value 1.3460428693912343 for feature 10, DI value: 2.7563483564239206, C ratio: 0.18176968225181867\n",
      "max value 0.9712194667582096 for feature 4, DI value: 1.8325216595562932, C ratio: 0.021248928064011352\n",
      "max value 0.9980106349693216 for feature 9, DI value: 1.9569890463794077, C ratio: 0.12295332239337542\n",
      "max value 0.9746667786535503 for feature 15, DI value: 1.3728366060286243, C ratio: -0.11910692176015125\n",
      "max value 0.8496112573478319 for feature 1, DI value: 1.7130670393809015, C ratio: -0.02338521147691819\n",
      "max value 0.7875070502112804 for feature 7, DI value: 1.5538492729330786, C ratio: -0.060856942670878045\n",
      "max value 0.8082586448574612 for feature 0, DI value: 1.7883545050492093, C ratio: 0.02836152845832063\n",
      "max value 0.8064174292061752 for feature 14, DI value: 1.7284739593472658, C ratio: 0.02818707809923482\n",
      "max value 0.6683103963743617 for feature 8, DI value: 1.890660170798169, C ratio: 0.10947389379452233\n",
      "max value 0.6847746214480142 for feature 5, DI value: 1.535743406756958, C ratio: -0.024192691015737067\n",
      "max value 0.6042598841833414 for feature 11, DI value: 1.8426958313125081, C ratio: 0.10821675737722025\n",
      "max value 0.501451155601023 for feature 6, DI value: 1.9041956603721284, C ratio: 0.14214086324995978\n",
      "max value 0.5074153994306116 for feature 3, DI value: 1.5845174605304155, C ratio: 0.025117473486432562\n",
      "max value 0.3754326027552937 for feature 12, DI value: 1.8546477289684054, C ratio: 0.1510275366690732\n",
      "max value 0.3146845033525828 for feature 2, DI value: 1.7005532113158748, C ratio: 0.10891230581632355\n",
      "DIMRMR features serially\n",
      "[13, 10, 4, 9, 15, 1, 7, 0, 14, 8, 5, 11, 6, 3, 12, 2]\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "xk_mim = [] \n",
    "xk_mrmr = [] \n",
    "xk_dimrmr = [] \n",
    "\n",
    "loop_counter = 100 if (length-1)>100 else length-1 \n",
    "# print(feature_list)\n",
    "\n",
    "while len(xk_dimrmr) < loop_counter:\n",
    "    mi = [0] * length\n",
    "    mrmr = [-100] * length\n",
    "    c_ratios = [0] * length\n",
    "    di = [-100] * (length - 1)\n",
    "    dimrmr = [-100] * (length - 1)\n",
    "\n",
    "\n",
    "    for i in range(length - 1):\n",
    "        if (i in xk_dimrmr):\n",
    "            continue \n",
    "\n",
    "        icfk = get_mutual_info(i, length - 1) #calculation done for MIM\n",
    "        mi[i] = icfk    #I (c; fk )\n",
    "\n",
    "        ifkxk = 0 #1/f x I (fk ; Xk ) the 2nd term of mrmr\n",
    "        for j in range(len(xk_dimrmr)):\n",
    "            ifkxk += get_mutual_info(i, xk_dimrmr[j])\n",
    "\n",
    "        if (len(xk_dimrmr)):\n",
    "            ifkxk = ifkxk / len(xk_dimrmr)\n",
    "\n",
    "        mrmr[i] = icfk - ifkxk  #calculation done for MRMR\n",
    "        \n",
    "        #DIMRMRicfk\n",
    "        avg_dep = 0\n",
    "        iFcfk = 0\n",
    "        # print(feature_list[i])\n",
    "\n",
    "        for j in range(len(xk_dimrmr)):\n",
    "            avg_dep += conditional_mutual_info(i, length - 1, xk_dimrmr[j])\n",
    "            iFcfk += conditional_mutual_info(xk_dimrmr[j], length - 1, i)\n",
    "        \n",
    "        if (len(xk_dimrmr)):\n",
    "            avg_dep = avg_dep / len(xk_dimrmr);\n",
    "            iFcfk = iFcfk / len(xk_dimrmr);\n",
    "\n",
    "        cr = avg_dep - get_mutual_info(i, length - 1)   #c ratio\n",
    "        c_ratios[i] = cr\n",
    "        cr_st = 2 * (cr) / (entropy_list[i] + entropy_list[length - 1]) # c ratio normalized\n",
    "    \n",
    "        di[i] = (2 + cr_st) * (iFcfk)   #DI, dynamic interaction weight\n",
    "\n",
    "        if len(xk_dimrmr) == 0:\n",
    "            di[i] = 1  \n",
    "        dimrmr[i] = (icfk - ifkxk) * di[i]\n",
    "    \n",
    "\n",
    "    (m, p) = max((v, i) for i, v in enumerate(dimrmr))\n",
    "    print(f'max value {m} for feature {p}, DI value: {di[p]}, C ratio: {c_ratios[p]}')\n",
    "    # if len(xk_dimrmr)==0:\n",
    "    #     print(p)\n",
    "    #     print(mrmr[p])\n",
    "    #     print(f'dimrmr: {dimrmr[p]}')\n",
    "    # print(dimrmr)\n",
    "\n",
    "    xk_dimrmr.append(p)\n",
    "\n",
    "\n",
    "\n",
    "print(\"DIMRMR features serially\")    \n",
    "print(xk_dimrmr)\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIMRMR features serially\n",
      "[15, 4, 9, 14, 13, 1, 0, 7, 10, 8, 5, 11, 6, 3, 12, 2]\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################## DIMRMR ########################\n",
    "print(\"DIMRMR features serially\")\n",
    "xk = []\n",
    "current_mi = 0\n",
    "loop_counter = 100 if (length-1)>100 else length-1\n",
    "# print(feature_list)\n",
    "\n",
    "while len(xk) < loop_counter:\n",
    "    di = [-100] * (length - 1)\n",
    "    dimrmr = [-100] * (length - 1)\n",
    "    dijmi = [-1] * (length - 1)\n",
    "    # print(f\"F = %s\"%feature_name(xk))\n",
    "\n",
    "    for i in range(length - 1):\n",
    "        if (i in xk):\n",
    "            continue\n",
    "\n",
    "        avg_dep = 0\n",
    "        iFcfk = 0\n",
    "        # print(feature_list[i])\n",
    "\n",
    "        for j in range(len(xk)):\n",
    "            avg_dep += conditional_mutual_info(i, length - 1, xk[j])\n",
    "            iFcfk += conditional_mutual_info(xk[j], length - 1, i)\n",
    "\n",
    "        if (len(xk)):\n",
    "            avg_dep = avg_dep / len(xk)\n",
    "            iFcfk = iFcfk / len(xk)\n",
    "\n",
    "        cr = avg_dep - get_mutual_info(i, length - 1)\n",
    "\n",
    "        cr_st = 2 * (cr) / (entropy_list[i] + entropy_list[length - 1])\n",
    "\n",
    "        di[i] = (2 + cr_st) * (iFcfk)\n",
    "\n",
    "        ifkxk = 0\n",
    "        IfkxkC = 0\n",
    "\n",
    "        icfk = get_mutual_info(i, length - 1)\n",
    "        for j in range(len(xk)):\n",
    "            ifkxk += get_mutual_info(i, xk[j])\n",
    "            IfkxkC += get_mutual_info(i, xk[j]) - conditional_mutual_info(i, xk[j], length - 1)\n",
    "\n",
    "        if (len(xk)):\n",
    "            ifkxk = ifkxk / len(xk)\n",
    "            IfkxkC = IfkxkC / len(xk)\n",
    "\n",
    "        dimrmr[i] = (icfk - ifkxk) * di[i]\n",
    "        dijmi[i] = (icfk - IfkxkC) * di[i]\n",
    "\n",
    "        # F = xk.copy();\n",
    "        # F.append(i)\n",
    "\n",
    "    (m, p) = max((v, i) for i, v in enumerate(dimrmr))\n",
    "    xk.append(p)\n",
    "\n",
    "print(xk)\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Random Forest Accuracy\n",
      "0.8258064516129032\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators': [200, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion':['gini', 'entropy', 'log_loss']}\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "clf = GridSearchCV(rfc, parameters)\n",
    "column_positions = [255, 29, 114, 119, 193, 77]\n",
    "x = data.iloc[:, column_positions]\n",
    "y = data['class'];\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1, stratify=y)\n",
    "clf.fit(x, y)\n",
    "sorted(clf.cv_results_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "print(\"Random Forest Accuracy\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 0 Random Forest Accuracy: Using features [255, 29, 114]\n",
      "0.646236559139785\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 1 Random Forest Accuracy: Using features [255, 29, 119]\n",
      "0.6209677419354839\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 2 Random Forest Accuracy: Using features [255, 29, 193]\n",
      "0.5924731182795699\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 3 Random Forest Accuracy: Using features [255, 29, 77]\n",
      "0.6016129032258064\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 4 Random Forest Accuracy: Using features [255, 114, 119]\n",
      "0.6204301075268818\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 5 Random Forest Accuracy: Using features [255, 114, 193]\n",
      "0.5865591397849462\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 6 Random Forest Accuracy: Using features [255, 114, 77]\n",
      "0.6403225806451613\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 7 Random Forest Accuracy: Using features [255, 119, 193]\n",
      "0.5736559139784946\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 8 Random Forest Accuracy: Using features [255, 119, 77]\n",
      "0.6118279569892473\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 9 Random Forest Accuracy: Using features [255, 193, 77]\n",
      "0.5903225806451613\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 10 Random Forest Accuracy: Using features [29, 114, 119]\n",
      "0.6172043010752688\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 11 Random Forest Accuracy: Using features [29, 114, 193]\n",
      "0.7053763440860215\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 12 Random Forest Accuracy: Using features [29, 114, 77]\n",
      "0.6279569892473118\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 13 Random Forest Accuracy: Using features [29, 119, 193]\n",
      "0.6505376344086021\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 14 Random Forest Accuracy: Using features [29, 119, 77]\n",
      "0.5956989247311828\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 15 Random Forest Accuracy: Using features [29, 193, 77]\n",
      "0.6591397849462366\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 16 Random Forest Accuracy: Using features [114, 119, 193]\n",
      "0.6854838709677419\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 17 Random Forest Accuracy: Using features [114, 119, 77]\n",
      "0.6220430107526882\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 18 Random Forest Accuracy: Using features [114, 193, 77]\n",
      "0.7118279569892473\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 19 Random Forest Accuracy: Using features [119, 193, 77]\n",
      "0.6666666666666666\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "items = [255, 29, 114, 119, 193, 77]\n",
    "selected_combinations = list(combinations(items, 3))\n",
    "\n",
    "tries = len(selected_combinations)\n",
    "\n",
    "for i in range(0, (tries)):\n",
    "    features = list(selected_combinations[i])\n",
    "\n",
    "    parameters = {'n_estimators': [200, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion':['gini', 'entropy', 'log_loss']}\n",
    "    rfc=RandomForestClassifier(random_state=42)\n",
    "    clf = GridSearchCV(rfc, parameters)\n",
    "    x = data.iloc[:, features]\n",
    "    y = data['class'];\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1, stratify=y)\n",
    "    clf.fit(x, y)\n",
    "    sorted(clf.cv_results_)\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    predictions = clf.predict(x_test)\n",
    "    print(f\"Try no. {i} Random Forest Accuracy: Using features {features}\")\n",
    "    print(accuracy_score(y_test, predictions))\n",
    "    print(\"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
