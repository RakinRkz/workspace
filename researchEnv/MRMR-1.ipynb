{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3om5b7ViaZ0_",
    "outputId": "4840f409-cdd0-423e-ada8-5fc4ad97c4c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: caimcaim in ./lib/python3.8/site-packages (0.3)\n",
      "Requirement already satisfied: pandas in ./lib/python3.8/site-packages (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in ./lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied: xgboost in ./lib/python3.8/site-packages (1.7.5)\n",
      "Requirement already satisfied: numpy in ./lib/python3.8/site-packages (from caimcaim) (1.24.3)\n",
      "Requirement already satisfied: sklearn in ./lib/python3.8/site-packages (from caimcaim) (0.0.post5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in ./lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install caimcaim pandas scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "J9pec9xsYESA",
    "outputId": "940341e9-2204-43e7-af39-967448623870"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from IPython.display import  clear_output\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from caimcaim import CAIMD\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CKNVGHWvYKlA"
   },
   "outputs": [],
   "source": [
    "def entropy(X):\n",
    "    unique, count = np.unique(X, return_counts=True, axis=0)\n",
    "    prob = count / len(X)\n",
    "    en = np.sum((-1) * prob * np.log2(prob))\n",
    "    return \n",
    "\n",
    "# Joint Entropy H(x,y)\n",
    "def joint_entropy(X, Y):\n",
    "    XY = np.c_[X, Y] \n",
    "    return entropy(XY)\n",
    "\n",
    "# Joint Entropy H(x,y,z)\n",
    "def joint_entropy_3(X, Y, Z):\n",
    "    XYZ = np.c_[X, Y, Z]\n",
    "    return entropy(XYZ)\n",
    "\n",
    "# Conditional Entropy X given Y  H(x|y)\n",
    "def conditional_entropy(X, Y):\n",
    "    return joint_entropy(X, Y) - entropy(Y)\n",
    "\n",
    "def ret_joint_entropy3(x,y):\n",
    "    if(x<y):\n",
    "        return joint_entropy_list3[x][y]\n",
    "    else:\n",
    "        return joint_entropy_list3[y][x]\n",
    "    \n",
    "\n",
    "def ret_joint_entropy(x,y):\n",
    "    if(x<y):\n",
    "        return joint_entropy_list[x][y]\n",
    "    else:\n",
    "        return joint_entropy_list[y][x]\n",
    "    \n",
    "#### H(x,y|z)\n",
    "def conditional_join_entropy(x, y, z):\n",
    "    if x == length - 1:\n",
    "        return ret_joint_entropy3(y, z) - entropy_list[z] \n",
    "    elif y == length - 1:\n",
    "        return ret_joint_entropy3(x, z) - entropy_list[z] \n",
    "    else:\n",
    "        return ret_joint_entropy3(x, y) - entropy_list[z] \n",
    "\n",
    "##### I(x,y)\n",
    "def get_mutual_info(x, y):\n",
    "    return entropy_list[x] + entropy_list[y] - ret_joint_entropy(x, y)\n",
    "\n",
    "########## I(x,y|z)\n",
    "def conditional_mutual_info(x, y, z):\n",
    "    cxz = ret_joint_entropy(x, z)-entropy_list[z]\n",
    "    cyz = ret_joint_entropy(y, z)-entropy_list[z]\n",
    "    return cxz + cyz - conditional_join_entropy(x, y, z)\n",
    "\n",
    "##### correlation\n",
    "def return_corelation(x, y):\n",
    "    size = len(x)\n",
    "    ux = x.sum() / size\n",
    "    uy = y.sum() / size\n",
    "\n",
    "    xmux = x - ux\n",
    "    ymuy = y - uy\n",
    "\n",
    "    xmuxymuy = xmux * ymuy \n",
    "\n",
    "    cov = xmuxymuy.sum() / (size - 1)\n",
    "\n",
    "    var_x = xmux * xmux\n",
    "    var_x = var_x.sum() / (size - 1)\n",
    "\n",
    "    var_y = ymuy * ymuy\n",
    "    var_y = var_y.sum() / (size - 1)\n",
    "\n",
    "    sd_x = math.sqrt(var_x)\n",
    "    sd_y = math.sqrt(var_y)\n",
    "\n",
    "    co_xy = cov / (sd_x * sd_y)\n",
    "\n",
    "    return co_xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "2CH2HqKPY3JP"
   },
   "outputs": [],
   "source": [
    "def feature_name(arr):\n",
    "    name = \"{\"\n",
    "    for i in range(len(arr)):\n",
    "        if i > 0:\n",
    "            name = name + \", \"\n",
    "\n",
    "        name = name + feature_list[arr[i]]\n",
    "\n",
    "    name = name + \"}\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "jdd8RosuY6bI"
   },
   "outputs": [],
   "source": [
    "def feature_array(arr):\n",
    "    name = []\n",
    "    for i in range(len(arr)):\n",
    "        name.append(feature_list[arr[i]])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "1eEHsioDY9DW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "nXOR_xGzY_q_"
   },
   "outputs": [],
   "source": [
    "# selection accuracies\n",
    "\n",
    "def selection_accurecy_svm(selected_features):\n",
    "    x = data[selected_features] \n",
    "    y = data['class'] \n",
    "\n",
    "    model = SVC(gamma='auto', C=10, kernel='linear')\n",
    "    accuracy = cross_validation(model, x, y)\n",
    "    return accuracy \n",
    "\n",
    "def selection_accurecy_dt(selected_features):\n",
    "\n",
    "    x = data[selected_features] \n",
    "    y = data['class'] \n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    accuracy = cross_validation(model, x, y)\n",
    "    return accuracy \n",
    "\n",
    "def selection_accurecy_KNN(selected_features):\n",
    "\n",
    "  x = data[selected_features] \n",
    "  y = data['class'] \n",
    "\n",
    "  model = KNeighborsClassifier(n_neighbors=3)\n",
    "  accuracy = cross_validation(model, x, y)\n",
    "  return accuracy \n",
    "\n",
    "  return accuracy_score(y_test, predictions)\n",
    "\n",
    "def selection_accurecy_nb(selected_features):\n",
    "\n",
    "  x = data[selected_features] \n",
    "  y = data['class'] \n",
    "\n",
    "  model = GaussianNB()\n",
    "\n",
    "  accuracy = cross_validation(model, x, y)\n",
    "  return accuracy \n",
    "\n",
    "def selection_accurecy_xgb(selected_features):\n",
    "    x = data[selected_features] \n",
    "    y = data['class'] \n",
    "\n",
    "    model = XGBClassifier()\n",
    "\n",
    "    accuracy = cross_validation(model, x, y)\n",
    "    return accuracy \n",
    "\n",
    "# cross validation\n",
    "def cross_validation(model, _X, _y):\n",
    "    _scoring = ['accuracy', 'precision', 'recall', 'test_score']\n",
    "    results = cross_validate(estimator=model,\n",
    "                             X=_X,\n",
    "                             y=_y,\n",
    "                             cv=10,\n",
    "                             # scoring=_scoring,\n",
    "                             return_train_score=True)\n",
    "\n",
    "    return results['test_score'].mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "FhC5EJsbZTfP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-e0ni8-KZcQH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10992, 17)\n"
     ]
    }
   ],
   "source": [
    "main_data = pd.read_csv(\"pendigits.csv\")\n",
    "clear_output()\n",
    "print(main_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4j-hlntbZfoW"
   },
   "outputs": [],
   "source": [
    "feature_list = main_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "X57ML-poZih1"
   },
   "outputs": [],
   "source": [
    "caim = CAIMD()\n",
    "x = main_data[feature_list[:-1]] \n",
    "y = main_data['class'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "IeDFXSSVZnt_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0  GLOBAL CAIM  97.98861085672317\n",
      "# 1  GLOBAL CAIM  127.52179668015063\n",
      "# 2  GLOBAL CAIM  70.69479583427037\n",
      "# 3  GLOBAL CAIM  101.67496475466642\n",
      "# 4  GLOBAL CAIM  109.78659760885364\n",
      "# 5  GLOBAL CAIM  146.48743397661866\n",
      "# 6  GLOBAL CAIM  98.85261390017756\n",
      "# 7  GLOBAL CAIM  162.63023326307626\n",
      "# 8  GLOBAL CAIM  72.82436463178126\n",
      "# 9  GLOBAL CAIM  118.59612313091051\n",
      "# 10  GLOBAL CAIM  76.70440033288963\n",
      "# 11  GLOBAL CAIM  111.99841534555728\n",
      "# 12  GLOBAL CAIM  80.75074886932973\n",
      "# 13  GLOBAL CAIM  166.7675540264832\n",
      "# 14  GLOBAL CAIM  109.94047950292438\n",
      "# 15  GLOBAL CAIM  184.838964313185\n"
     ]
    }
   ],
   "source": [
    "x_disc = caim.fit_transform(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "j4Cmd5OjZqcn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10992, 17)\n"
     ]
    }
   ],
   "source": [
    "data = x_disc\n",
    "data['class'] = y \n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "BOKxhTlJZ3NP",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MrMr\n",
      "[195, 75, 114, 167, 242, 119, 189, 29, 163, 225, 100, 92, 212, 151, 222, 120, 18, 146, 209, 12, 157, 179, 76, 84, 226, 135, 221, 147, 91, 228, 194, 13, 99, 173, 196, 104, 59, 210, 136, 131, 77, 177, 227, 188, 3, 168, 115, 45, 238, 141, 241, 180, 162, 93, 14, 193, 152, 243, 116, 103, 205, 60, 211, 130, 34, 164, 22, 178, 206, 61, 83, 229, 109, 237, 183, 11, 204, 90, 19, 145, 30, 213, 172, 85, 98, 208, 244, 190, 148, 125, 166, 46, 219, 129, 224, 27, 101, 161, 4, 220]\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"MrMr feature serially\")\n",
    "xk = [] \n",
    "current_mi = 0 \n",
    "loop_counter = 100 if (length-1)>100 else length-1 \n",
    "# print(feature_list)\n",
    "\n",
    "while len(xk) < loop_counter:\n",
    "    mi = [-100] * length\n",
    "\n",
    "    for i in range(length - 1):\n",
    "        if (i in xk):\n",
    "            continue \n",
    "\n",
    "        Ixc = get_mutual_info(i, length - 1) \n",
    "        Ixmxs = 0 \n",
    "        for j in range(len(xk)):\n",
    "            Ixmxs += get_mutual_info(xk[j], i) \n",
    "\n",
    "        if (len(xk)):\n",
    "            Ixmxs = Ixmxs / len(xk) \n",
    "\n",
    "        mi[i] = Ixc - Ixmxs \n",
    "\n",
    "    (m, p) = max((v, i) for i, v in enumerate(mi))\n",
    "    # print(mi)\n",
    "    xk.append(p)\n",
    "    # print(feature_name(xk))\n",
    "\n",
    "    # accurecy = selection_accurecy_dt(feature_array(xk))\n",
    "    # accurecy2 = selection_accurecy_svm(feature_array(xk))\n",
    "    # accurecy3 = selection_accurecy_KNN(feature_array(xk))\n",
    "    # accurecy4 = selection_accurecy_nb(feature_array(xk))\n",
    "    # accurecy5 =0\n",
    "    # print(f\"%s %s  %s %s  %s\" % (accurecy, accurecy2, accurecy3, accurecy4, accurecy5)) \n",
    "\n",
    "print(xk)\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[195, 75, 114, 167, 242, 119, 189, 29, 163, 225, 100, 92, 212, 151, 222, 120, 18, 146, 209, 12, 157, 179, 76, 84, 226, 135, 221, 147, 91, 228, 194, 13, 99, 173, 196, 104, 59, 210, 136, 131, 77, 177, 227, 188, 3, 168, 115, 45, 238, 141, 241, 180, 162, 93, 14, 193, 152, 243, 116, 103, 205, 60, 211, 130, 34, 164, 22, 178, 206, 61, 83, 229, 109, 237, 183, 11, 204, 90, 19, 145, 30, 213, 172, 85, 98, 208, 244, 190, 148, 125, 166, 46, 219, 129, 224, 27, 101, 161, 4, 220]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0\n",
      "x: 1\n",
      "x: 2\n",
      "x: 3\n",
      "x: 4\n",
      "x: 5\n",
      "x: 6\n",
      "x: 7\n",
      "x: 8\n",
      "x: 9\n",
      "x: 10\n",
      "x: 11\n",
      "x: 12\n",
      "x: 13\n",
      "x: 14\n",
      "x: 15\n",
      "x: 16\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[46], line 18\u001b[0m\n",
      "\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(length):\n",
      "\u001b[1;32m     17\u001b[0m   \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(length):\n",
      "\u001b[0;32m---> 18\u001b[0m     conditional_entropy_list[i][j] \u001b[39m=\u001b[39m ret_joint_entropy(i,j)\u001b[39m-\u001b[39;49mentropy_list[j];\n",
      "\u001b[1;32m     19\u001b[0m     covariance_list[i][j] \u001b[39m=\u001b[39m return_corelation(data[feature_list[i]],data[feature_list[j]])\n",
      "\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpopulate Data\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "length=len(feature_list)\n",
    "entropy_list = [0]*length;\n",
    "joint_entropy_list = defaultdict(dict);\n",
    "conditional_entropy_list = defaultdict(dict);\n",
    "joint_entropy_list3 = defaultdict(dict);\n",
    "covariance_list = defaultdict(dict);\n",
    "for i in range(length):\n",
    "    entropy_list[i] = entropy(data[feature_list[i]])\n",
    "    for j in range(i,length):\n",
    "        joint_entropy_list[i][j] = joint_entropy(data[feature_list[i]],data[feature_list[j]])\n",
    "        joint_entropy_list3[i][j] = joint_entropy_3(data[feature_list[i]],data[feature_list[j]],data[feature_list[length-1]]);\n",
    "\n",
    "    print(\"x: %s\" %(i))\n",
    "\n",
    "\n",
    "for i in range(length):\n",
    "  for j in range(length):\n",
    "    conditional_entropy_list[i][j] = ret_joint_entropy(i,j)-entropy_list[j];\n",
    "    covariance_list[i][j] = return_corelation(data[feature_list[i]],data[feature_list[j]])\n",
    "\n",
    "print(\"populate Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': [200, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion':['gini', 'entropy', 'log_loss']}\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "clf = GridSearchCV(rfc, parameters)\n",
    "x = data[feature_list[:-1]]\n",
    "y = data['class'] \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1, stratify=y)\n",
    "clf.fit(x, y)\n",
    "sorted(clf.cv_results_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "print(\"Random Forest Accuracy with all columns\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Random Forest Accuracy\n",
      "0.8462365591397849\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators': [200, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion':['gini', 'entropy', 'log_loss']}\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "clf = GridSearchCV(rfc, parameters)\n",
    "column_positions = [195, 75, 114, 167, 242, 119]\n",
    "x = data.iloc[:, column_positions]\n",
    "y = data['class'] \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1, stratify=y)\n",
    "clf.fit(x, y)\n",
    "sorted(clf.cv_results_)\n",
    "print(clf.best_params_)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "print(f\"Random Forest Accuracy with features: {column_positions}\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 0 Random Forest Accuracy: Using features [195, 75, 114]\n",
      "0.6758064516129032\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 1 Random Forest Accuracy: Using features [195, 75, 167]\n",
      "0.6381720430107527\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 2 Random Forest Accuracy: Using features [195, 75, 242]\n",
      "0.5908602150537634\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 3 Random Forest Accuracy: Using features [195, 75, 119]\n",
      "0.6596774193548387\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 4 Random Forest Accuracy: Using features [195, 114, 167]\n",
      "0.6704301075268817\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 5 Random Forest Accuracy: Using features [195, 114, 242]\n",
      "0.6166666666666667\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 6 Random Forest Accuracy: Using features [195, 114, 119]\n",
      "0.6682795698924732\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 7 Random Forest Accuracy: Using features [195, 167, 242]\n",
      "0.5870967741935483\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 8 Random Forest Accuracy: Using features [195, 167, 119]\n",
      "0.6747311827956989\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 9 Random Forest Accuracy: Using features [195, 242, 119]\n",
      "0.5913978494623656\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 10 Random Forest Accuracy: Using features [75, 114, 167]\n",
      "0.6440860215053763\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 11 Random Forest Accuracy: Using features [75, 114, 242]\n",
      "0.6629032258064517\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 12 Random Forest Accuracy: Using features [75, 114, 119]\n",
      "0.614516129032258\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 13 Random Forest Accuracy: Using features [75, 167, 242]\n",
      "0.6069892473118279\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 14 Random Forest Accuracy: Using features [75, 167, 119]\n",
      "0.6623655913978495\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 15 Random Forest Accuracy: Using features [75, 242, 119]\n",
      "0.6612903225806451\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "Try no. 16 Random Forest Accuracy: Using features [114, 167, 242]\n",
      "0.6532258064516129\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 17 Random Forest Accuracy: Using features [114, 167, 119]\n",
      "0.65\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 18 Random Forest Accuracy: Using features [114, 242, 119]\n",
      "0.6580645161290323\n",
      "\n",
      "\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Try no. 19 Random Forest Accuracy: Using features [167, 242, 119]\n",
      "0.671505376344086\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "items = [195, 75, 114, 167, 242, 119]\n",
    "selected_combinations = list(combinations(items, 3))\n",
    "\n",
    "tries = len(selected_combinations)\n",
    "\n",
    "for i in range(0, (tries)):\n",
    "    features = list(selected_combinations[i])\n",
    "\n",
    "    parameters = {'n_estimators': [200, 500], 'max_features': ['sqrt', 'log2'], 'max_depth': [4, 5, 6, 7, 8], 'criterion':['gini', 'entropy', 'log_loss']}\n",
    "    rfc=RandomForestClassifier(random_state=42)\n",
    "    clf = GridSearchCV(rfc, parameters)\n",
    "    x = data.iloc[:, features]\n",
    "    y = data['class'] \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=1, stratify=y)\n",
    "    clf.fit(x, y)\n",
    "    sorted(clf.cv_results_)\n",
    "    print('\\n\\n')\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    predictions = clf.predict(x_test)\n",
    "    print(f\"Try no. {i} Random Forest Accuracy: Using features {features}\")\n",
    "    print(accuracy_score(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
